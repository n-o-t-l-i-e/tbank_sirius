# Описание

Этот проект использует предобученные модели **Mask R-CNN** и **GPT-2** для обработки изображений и генерации описаний объектов. В процессе обработки изображения маскируются с использованием Mask R-CNN, удаляется фон, и можно заменить его на однотонный цвет или другое изображение. Затем GPT-2 генерирует текстовое описание объектов, определенных в изображениях.

## Используемые библиотеки

- **torch**: Основная библиотека для работы с нейронными сетями.
- **torchvision**: Модели компьютерного зрения, включая Mask R-CNN.
- **transformers**: Модели обработки естественного языка, включая GPT-2.
- **Pillow**: Работа с изображениями (открытие и преобразование).
- **opencv-python**: Обработка изображений.
- **numpy**: Для работы с массивами и матричными операциями.

## Установка

1. Клонируйте репозиторий или скопируйте код в свою рабочую директорию.
2. Убедитесь, что у вас установлена Python версия 3.7 или выше.
3. Установите необходимые зависимости с помощью команды:

```bash
pip install -r requirements.txt
```

## Использование

### Основные функции:

- **`load_detection_model()`**: Загрузка предобученной модели Mask R-CNN для детекции объектов.
- **`get_mask_and_class(image, detection_model, device)`**: Предсказание маски и класса объекта на изображении.
- **`refine_mask(mask, target_size)`**: Обработка маски для удаления мелких артефактов и улучшения качества.
- **`mask_image(image, mask)`**: Применение маски к изображению для удаления фона.
- **`change_background(image, mask, bg_type="solid", bg_color=(255, 255, 255), bg_image=None)`**: Замена фона изображения на однотонный цвет или другое изображение.
- **`create_description(class_name, gpt_model, tokenizer)`**: Генерация текстового описания объекта с использованием GPT-2.

### Процесс обработки:

1. Изображение обрабатывается моделью Mask R-CNN для выделения объекта и создания маски.
2. Маска применяется для удаления фона с изображения.
3. Фон заменяется на заданный (однотонный цвет или другое изображение).
4. На основе распознанного объекта генерируется текстовое описание с помощью модели GPT-2.

### Пример использования:

Для обработки изображений, находящихся в папке `sirius_data/sirius_data`, и сохранения результатов в папку `output_images`, выполните следующую команду:

```python
if __name__ == "__main__":
    input_dir = "sirius_data/sirius_data"  # Папка с исходными изображениями
    output_dir = "output_images"  # Папка для сохранения результатов
    
    process_image_folder(input_dir, output_dir, bg_type="solid", bg_color=(220, 220, 220))
```
### Входные и выходные данные:

- Входные изображения должны быть названы в формате `0.jpg`, `1.jpg`, ..., `499.jpg` и находиться в указанной папке.
- Выходные файлы будут сохранены в папке `output_images` в виде:
  - Обработанное изображение с именем `processed_X.jpg` (где `X` — это исходное имя файла).
  - Текстовое описание будет сохранено в виде `description_X.jpg.txt`.

### Настройки:

- **`bg_type`**: Указывает тип фона. Может быть `"solid"` (для однотонного цвета) или `"image"` (для использования другого изображения).
- **`bg_color`**: Цвет фона в формате `(R, G, B)` (по умолчанию — белый).
- **`bg_image_path`**: Путь к изображению, если требуется заменить фон на изображение.

### Примечания:

- Модель **Mask R-CNN** распознает объекты на изображениях и выделяет их масками. Классы объектов берутся из **COCO dataset**.
- **GPT-2** генерирует текст на основе имени класса объекта.
